# Comprehensive Literature Survey: Causal Discovery, Knowledge Graphs, and Causal Inference (2024)

## Overview

This literature survey systematically addresses foundational and technical research questions concerning state-of-the-art causal discovery methodologies, causal knowledge graph systems, and neural architectures for causal inference from unstructured data. Based on recent publications through 2024-2025, the field has experienced significant advances in algorithm efficiency, multimodal data handling, large language model integration, and real-time graph updating mechanisms. This survey synthesizes findings across constraint-based and score-based approaches, explores emerging LLM-driven causal discovery paradigms, and examines practical implementations of causal reasoning in knowledge graph systems.

## Foundational Questions on Causal Discovery Algorithms

### State-of-the-Art Algorithms in 2024

The landscape of causal discovery algorithms as of 2024 encompasses both mature established methods and emerging hybrid approaches that integrate machine learning with traditional statistical techniques. **The principal algorithmic families include constraint-based methods, score-based methods, optimization-based approaches, and recently developed LLM-augmented discovery systems**.[1][2][3][4]

Constraint-based algorithms represent a foundational category that uses conditional independence testing to recover causal structures. The **PC (Peter-Clark) algorithm** initiates the discovery process with a fully connected undirected graph and iteratively removes edges based on conditional independence tests with increasing conditional set sizes. This approach remains one of the most widely studied algorithms for causal discovery from observational data. The **FCI (Fast Causal Inference) algorithm** extends the PC framework by relaxing the causal sufficiency assumption, enabling it to handle latent confounders and selection bias. The FCI algorithm employs additional orientation rules to identify potential latent common causes and distinguishes between directed and bidirected edges, producing a partial ancestral graph (PAG) that represents the equivalence class of causal graphs with latent variables.[5][3][1]

Score-based methods follow a fundamentally different paradigm by optimizing model fit rather than testing independence relations. **The GES (Greedy Equivalence Search) algorithm** and its faster variant **fGES** use Bayesian scores to search through the space of causal models. More recently, **NOTEARS** (No Tears) introduced an innovation in score-based discovery by formulating causal discovery as a continuous optimization problem under the linear structural equation model (LSEM) framework, incorporating an acyclicity constraint via Lagrange multipliers. This breakthrough enabled the application of gradient-based optimization methods to learn directed acyclic graphs (DAGs).[6]

Recent advances have introduced **hybrid methods integrating explainability techniques with machine learning**. The **ReX method** combines ML models with Shapley values for feature attribution to identify causal relationships, demonstrating superior performance on synthetic datasets with non-linear and additive noise models while achieving precision of 0.952 on the Sachs single-cell protein-signaling dataset.[7]

**LLM-based causal discovery represents a paradigm shift**, leveraging the knowledge and reasoning capabilities of large language models. Novel frameworks employ **breadth-first search (BFS) approaches that require only linear numbers of queries** rather than the quadratic complexity of pairwise approaches. These methods eliminate the requirement for observational data and training time, instead utilizing metadata and variable descriptions in natural language, resembling how domain experts construct causal graphs.[8]

### Comparative Analysis: Constraint-Based vs. Score-Based Methods

The theoretical and practical distinctions between constraint-based and score-based causal discovery algorithms warrant detailed examination. **Constraint-based approaches operate by testing conditional independence relationships**; they begin with maximal model assumptions and progressively eliminate edges incompatible with the observed conditional independence structure. This approach produces a Markov equivalence class of causal graphs, typically represented as a partially directed acyclic graph (PDAG).[2][1]

**Score-based methods, conversely, optimize an objective function that scores competing causal structures against observed data**. These algorithms employ search procedures—such as greedy equivalence search or simulated annealing—to navigate the space of DAGs, seeking the structure that maximizes some scoring criterion (e.g., Bayesian Information Criterion, BIC). The fundamental advantage of score-based approaches lies in their flexibility; they accommodate non-linear relationships and can incorporate domain knowledge through prior distributions on structures.[6]

**Comparative empirical evaluations reveal distinct performance profiles across different data characteristics**. Constraint-based algorithms demonstrate robustness to latent confounders through variants such as FCI and RFCI, which can identify potential latent common causes and adjust their output accordingly. Algorithms like FCI and RFCI explicitly handle settings where causal sufficiency does not hold, proving theoretically sound under simple σ-faithful Structural Causal Models. This capability renders them particularly valuable in domains where unobserved confounding is suspected.[3][9]

Score-based methods generally exhibit superior performance in scenarios with large sample sizes and clean continuous data, as they leverage the full information content of the data distribution rather than relying solely on independence tests, which can be sensitive to statistical power and multiple testing corrections. However, score-based approaches traditionally assume causal sufficiency—the assumption that all common causes are observed—which may be violated in practice. The NOTEARS algorithm, despite its computational advantages, has been shown to lack scale-invariance in certain practical settings, limiting its applicability without careful feature preprocessing.[10]

### Challenges and Breakthroughs in Causal Learning from Text Data

Learning causal graphs from unstructured text presents distinctive challenges that differ from tabular or time-series data. **The primary obstacles include event boundary deviation, distinguishing implicit from explicit causality, capturing inter-sentential causal relations, identifying multimodal factors, and handling intra- and inter-modal interactions**.[11][12][13]

Event boundary deviation occurs because causal events are presented as continuous text spans, and models must accurately demarcate event boundaries without including extraneous information or excluding relevant details. Implicit causality poses a particularly vexing problem, as causal relationships are not always explicitly marked by connectives (e.g., "because," "caused by") but may require comprehension and commonsense reasoning.[12][11]

**Recent breakthroughs address these challenges through multiple complementary approaches**. The **MLLM-CD framework** represents a significant advancement, extending causal discovery to multimodal unstructured data by integrating multimodal large language models (MLLMs). This framework comprises three key components: (1) a contrastive factor discovery module that identifies genuine multimodal factors based on interactions from contrastive sample pairs, (2) a statistical causal structure discovery module that infers relationships among discovered factors, and (3) an iterative multimodal counterfactual reasoning module that refines discoveries iteratively.[14]

The **Contextual Highlighting Event Causality Extraction (CHECE) framework** addresses event boundary deviation and causal event pair mismatching by proposing an Event Highlighter, an Event Concretization Module, and a Contextual Event Causality Matching mechanism. This method leverages LLMs to optimize task definitions, evolve datasets, and diversify content templates to force models to learn causality from context.[13]

**LLMs have demonstrated exceptional capability in extracting causal relationships from text**, handling both explicit causality marked by connectives and implicit causality requiring commensical reasoning. Research confirms that LLMs effectively extract causal variables and event sequences by synthesizing linguistic and background knowledge, significantly improving causal pair extraction over formulaic approaches.[15]

### Pearl's Do-Calculus in Modern Knowledge Graph Systems

Pearl's do-calculus provides a formal calculus for reasoning about interventions and causal effects in graphical causal models. **In modern knowledge graph systems, do-calculus enables the estimation of causal queries—interventional distributions of the form "When we perturb X, what is the effect on its descendent Y?"**.[16]

**The application of do-calculus in knowledge graphs requires three key components: (1) the qualitative topology of the causal graph structure, (2) experimental measurements characterizing causal relationships quantitatively, and (3) identifiability conditions**. Latent Variable Model (LVM)-based estimators of causal queries are provably accurate when queries are identifiable according to Pearl's do-calculus, even when parameters are not uniquely identified or when the true number of latent variables is unknown.[16]

The practical utility of do-calculus in knowledge graph query answering involves computing do-calculus expressions to determine whether specific interventional queries are identifiable. This requires checking whether the target causal quantity can be computed from the observed probability distribution using the three rules of do-calculus: the rule of ignoring observations, the rule of action/observation exchange, and the rule of ignoring actions. Knowledge graph systems increasingly integrate these formal machinery to provide interpretable, causally-grounded query responses.[16]

### Causal Knowledge Graphs vs. Traditional Knowledge Graphs

**Causal knowledge graphs (CKGs) fundamentally differ from traditional knowledge graphs (KGs) by explicitly representing cause-and-effect relationships rather than mere associative connections**. Traditional knowledge graphs link entities through associative relationships—for example, "Paris is the capital of France"—without explaining causal mechanisms or predicting outcomes. They lack causal context, making it difficult to predict consequences of interventions or understand how one entity influences another.[17]

**CKGs incorporate directed edges representing causal relationships, with arrows pointing from causes to effects**. For illustrative purposes, consider a cardiovascular disease example: in a CKG, directed edges would indicate how smoking causally influences lung cancer risk, how physical activity affects cardiovascular health, and how biological factors like blood pressure and cholesterol contribute to disease development. This rich causal structure enables **enhanced data analysis, predictive and prescriptive analytics, and a broad range of applications** spanning healthcare, business intelligence, and scientific discovery.[17]

The representational advantages of CKGs extend to reasoning capabilities. **Traditional KGs support entity linking and relation retrieval through pattern matching**; CKGs additionally support **counterfactual reasoning, intervention simulation, and causal pathway analysis**. These capabilities prove essential for applications requiring decision-support, such as clinical recommendations, policy impact assessment, and root cause analysis.[17]

## Technical Implementation Dimensions

### Neural Architectures for Causal Relation Extraction

The effective extraction of causal relations from unstructured text necessitates carefully designed neural architectures that capture syntactic and semantic relationships. **Recent research identifies recurrent neural networks (RNNs), convolutional neural networks (CNNs), and graph convolutional networks (GCNs) as predominant deep learning approaches for causal relation extraction**.[11]

**Recurrent neural networks** process text sequentially, enabling them to develop robust understanding of sentence context and long-range dependencies critical for identifying causality across multiple tokens. Their ability to maintain hidden states that evolve with sequential input makes them particularly valuable for capturing temporal and logical precedence relationships inherent in causal statements.[11]

**Convolutional neural networks** identify patterns in text similar to how they detect visual patterns in images, allowing them to recognize causal expressions regardless of their position within a sentence. This position-invariant pattern recognition proves especially valuable for recognizing diverse causal connectives and constructions distributed throughout documents.[11]

**Graph convolutional networks** model relationships between different parts of sentences, potentially capturing complex causal structures by treating text as a graph where words are nodes and syntactic dependencies form edges. This approach enables GCNs to propagate information through the graph structure, allowing each node to incorporate features and connections of neighboring nodes—a mechanism directly analogous to how causal influences propagate through graphical causal models.[11]

**Context-enhanced transformers have emerged as high-performing architectures**, particularly when combined with domain-specific pre-training. The paper demonstrates that transformer-based contextual word embeddings from specialized pre-trained models such as BioBERT and RoBERTa work best across diverse target datasets. BioBERT-BiGRU architectures generalize robustly across varying web-based sources and annotation strategies, with emphasis on noun phrase localization through specialized metrics like F1_phrase.[12]

**Comparative analysis across multiple datasets reveals that transfer learning across causal relation datasets significantly improves performance**. Testing on datasets including CausalTimeBank, CauseNet, and SemEval datasets shows that models trained on diverse datasets achieve substantially better generalization. For example, CausalTimeBank demonstrated 21.86% improvement in F1_phrase scores over direct F1 scores, reflecting improved capture of implicit causality in temporal and event-driven texts.[12]

### Fine-Tuning and Prompting Large Language Models for Causal Extraction

Large language models represent a paradigm shift in causal relation extraction, offering capabilities that transcend traditional sequence labeling approaches. **Contemporary fine-tuning strategies for LLMs in causal relation extraction encompass domain-specific pre-training, prompt engineering, few-shot learning, and LLM-based dataset augmentation**.[18][13][15]

**Domain-specific pre-training** creates specialized foundation models before downstream task adaptation. BioBERT achieves this by pre-training BERT on biomedical literature, enabling superior performance on biomedical causal relation extraction tasks. This approach proves particularly effective because domain-specific vocabulary, abbreviations, and discourse patterns are encoded during the pre-training phase.[19]

**Fine-tuned LLMs demonstrate exceptional performance on standard benchmarks**. Empirical evaluations on TACRED, TACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show substantial improvements with fine-tuned models including Llama2-7B, Mistral-7B, and T5-Large. Notably, approaches on SemEVAL—where implicit relations predominate—surpass previous results, suggesting that fine-tuned LLMs capture implicit causal semantics more effectively than prior methods.[18]

**Prompt engineering techniques leverage LLMs' in-context learning capabilities without explicit fine-tuning**. Researchers structure prompts to clarify task definitions, provide exemplars, and elicit step-by-step reasoning about causal relationships. LLMs prove capable of handling both explicit causality marked by connectives and implicit causality requiring background knowledge synthesis.[13][15]

**LLM-based dataset repair and augmentation** represents an innovative application. The CHECE framework utilizes LLMs to fix datasets by enforcing carefully specified task definitions, repair event boundaries, and diversify content templates through synthetic generation. This approach addresses annotation inconsistencies and enhances model robustness to varied expression patterns.[13]

### Graph Neural Network Architectures for Causal Inference

Graph neural networks provide a natural computational substrate for causal inference on knowledge graphs, as they directly operate on graph-structured data and propagate information through causal dependencies. **Contemporary GNN architectures for causal inference include Graph Attention Networks (GATs), Graph Convolutional Networks (GCNs), causality-informed variants (CiGNN), dynamic spatio-temporal architectures (DyC-STG), and dual-attention embedding networks**.[20][21][22][23]

**Graph Attention Networks (GATs)** assign learnable attention weight coefficients to different neighbors, enabling the model to focus on the most influential entities and relationships during message passing. This attention mechanism proves particularly valuable for knowledge graphs where not all neighboring entities contribute equally to understanding a central entity's properties or causal role.[22]

**Graph Convolutional Networks (GCNs)** apply convolution concepts to non-Euclidean graph-structured data through neighborhood information aggregation via message passing. GCNs enhance knowledge representation by incorporating topological information, allowing central nodes to benefit from aggregated neighborhood features.[22]

**Causality-informed Graph Neural Networks (CiGNN)** explicitly integrate causal graph structure as prior knowledge into GNN architectures. In biomedical applications, CiGNN identifies causal graphs using constraint-based algorithms (such as FCI), then constructs GNN architectures where the graph topology directly reflects known causal associations between wearable features and outcome variables (e.g., blood pressure). This integration enables the GNN to derive causally-grounded representations that improve prediction accuracy.[20]

**Dynamic Causal Spatio-Temporal Graphs (DyC-STG)** address real-time scenarios where causal graph topology must adapt to reflect changing physical states. This framework features event-driven dynamic graph modules that adapt graph topology in real-time and causal reasoning modules that distill causally-aware representations by strictly enforcing temporal precedence. The architecture achieves state-of-the-art results in real-time credibility analysis for IoT systems, with F1-scores up to 0.930.[21]

**Dual-Attention Embedding Networks (D-AEN)** jointly learn representations of both entities and relations in knowledge graphs by incorporating bidirectional attention mechanisms and relation-specific attention. Bidirectional attention mechanisms measure the importance of neighborhoods with different relation directions for entity representation learning, while relation-specific attention measures neighborhood importance for relation representation learning. Results on FB15K-237 show Hits@1 improvement of 10.9% compared to second-ranked baselines.[23]

### Computational Complexity and Scalability Challenges

**Causal discovery algorithms face significant computational complexity challenges that limit their applicability to large-scale systems**. Linear programming (LP) formulations used in causal inference problems with unobserved confounders suffer from exponential growth in LP size as the number of edges in the causal graph increases. Traditional LP solvers quickly become intractable for graphs with dozens or hundreds of edges, rendering exact solutions infeasible.[24]

**The complexity of pairwise causal discovery approaches scales quadratically with the number of variables**. Previous LLM-based methods querying pairwise causal relationships between all variable pairs require \(O(n^2)\) queries for \(n\) variables, quickly becoming impractical as problem size increases. This quadratic scaling severely constrains applicability to real-world systems with hundreds or thousands of variables.[8]

**Recent algorithmic innovations substantially reduce computational requirements**. BFS-based LLM causal discovery approaches achieve linear query complexity, requiring only \(O(n)\) queries while still satisfying DAG constraints. This reduction from quadratic to linear complexity represents a fundamental breakthrough for scaling causal discovery to larger problems. Additionally, LP size reduction techniques that carefully consider the structure of causal queries—rather than treating all queries uniformly—allow exact computation of bounds for significantly larger graphs while maintaining solution quality.[24][8]

### Dynamic Causal Graph Updates and Real-Time Learning

Practical knowledge graph systems require mechanisms to dynamically incorporate new information while maintaining causal graph coherence and computational efficiency. **The INCADET framework pioneered incremental causal graph learning specifically designed for real-time scenarios**, demonstrating application to streaming cyberattack detection.[25]

**INCADET dynamically captures evolving system behavior by incrementally updating causal graphs across streaming time windows**. The framework comprises three specialized modules: (1) Early Symptom Detection that detects transitions in system status using divergence in edge-weight distributions across sequential causal graphs, (2) progressive graph refinement mechanisms, and (3) causal inference for anomaly scoring.[25]

**Event-driven dynamic graph modules** adapt graph topology in real-time to reflect physical state changes. Rather than recomputing entire causal structures from scratch when new data arrives, these approaches selectively update affected portions of the graph based on newly observed events. This targeted updating dramatically reduces computational overhead compared to full graph recomputation.[21]

**Streaming time window approaches** organize data into successive time windows, each processed to identify or refine causal relationships within that window. By restricting computation to recent data, these approaches maintain real-time responsiveness while avoiding the computational burden of reprocessing entire historical datasets.[25]

**Temporal precedence constraints ensure causality coherence in dynamic settings**. Rather than treating all dependencies symmetrically, dynamic causal systems explicitly enforce that causes precede effects temporally. This temporal ordering principle, enforced during both graph discovery and updating phases, maintains the fundamental asymmetry distinguishing causal relationships from mere correlation.[21]

## Synthesis and Research Frontiers

**The causal discovery field has matured substantially, evolving from purely statistical approaches toward hybrid methods that combine machine learning with formal causal theory**. The integration of LLMs into causal discovery pipelines represents a significant methodological shift, enabling discovery without observational data in certain domains while leveraging formal statistical methods when data is available.[14][8]

**Multimodal causal discovery emerges as a crucial frontier**, with the MLLM-CD framework demonstrating how to extract causal relationships from combinations of text, images, and other modalities simultaneously. This capability proves essential for real-world applications where information naturally spans multiple modalities.[14]

**Identifiability conditions for causal models remain an active research area**, particularly for multimodal and complex data structures. Establishing when causal effects are uniquely determinable from observed data, and developing algorithms to exploit these identifiability conditions computationally, continues to drive both theoretical and practical advances.[26][27]

**Computational scalability through algorithm restructuring**—such as reducing query complexity from quadratic to linear in LLM-based discovery—demonstrates that theoretical insights can yield dramatic practical improvements. Future research should continue exploring structural properties of causal discovery problems that enable pruning, approximation, and parallelization strategies.[8]

[1](https://arxiv.org/abs/1611.03977)
[2](https://pmc.ncbi.nlm.nih.gov/articles/PMC6510516/)
[3](https://fiveable.me/causal-inference/unit-10/constraint-based-algorithms/study-guide/5iUOkVRLvyUnYSGm)
[4](https://www.ijcai.org/proceedings/2025/1186.pdf)
[5](https://docs.actable.ai/causal_discovery.html)
[6](https://causaldm.github.io/Causal-Decision-Making/2_Causal_Structure_Learning/Causal%20Discovery.html)
[7](https://arxiv.org/html/2501.12706v1)
[8](https://arxiv.org/html/2402.01207v1)
[9](https://arxiv.org/abs/2005.00610)
[10](https://causalens.com/wp-content/uploads/2025/05/NOTEARS.pdf)
[11](https://pmc.ncbi.nlm.nih.gov/articles/PMC12621500/)
[12](https://arxiv.org/html/2503.06076v1)
[13](https://aclanthology.org/2024.neusymbridge-1.4.pdf)
[14](https://arxiv.org/html/2509.17784v2)
[15](https://dspace.ut.ee/bitstreams/402bde05-e6cc-41e4-b133-293c38e2b861/download)
[16](https://academic.oup.com/bioinformatics/article/38/Supplement_1/i350/6617530)
[17](https://adasci.org/how-causal-knowledge-graphs-outperform-traditional-knowledge-graphs/)
[18](https://arxiv.org/abs/2406.14745)
[19](https://arxiv.org/pdf/2208.01316.pdf)
[20](https://pmc.ncbi.nlm.nih.gov/articles/PMC11100861/)
[21](https://arxiv.org/abs/2509.06483)
[22](https://pmc.ncbi.nlm.nih.gov/articles/PMC10909163/)
[23](https://www.sciencedirect.com/science/article/abs/pii/S0957417422018243)
[24](https://proceedings.mlr.press/v162/shridharan22a/shridharan22a.pdf)
[25](https://arxiv.org/abs/2507.14387)
[26](https://arxiv.org/pdf/1202.3757.pdf)
[27](https://pmc.ncbi.nlm.nih.gov/articles/PMC11952583/)
[28](https://www.its.caltech.edu/~fehardt/papers/HEJ_UAI2014.pdf)
[29](https://arxiv.org/pdf/2305.10032.pdf)
[30](https://www.emergentmind.com/topics/fully-causal-architecture)
[31](https://www.sciencedirect.com/science/article/pii/S0031320325011549)
[32](https://proceedings.mlr.press/v202/kaltenpoth23a/kaltenpoth23a.pdf)
[33](https://www.youtube.com/watch?v=9GwQyvG06Qo)
[34](https://ceur-ws.org/Vol-3184/TEXT2KG_Paper_1.pdf)
[35](https://www.oaepublish.com/articles/ir.2022.17)
[36](https://statistik.tu-dortmund.de/storages/statistik/r/Downloads/Studium/Vorlesungsverzeichnis/Seminare_und_Spezialgebiete_SS_2023/SoSe_2025/4._Causality__Invariance___Distributional_Robustness_Marx_SoSe25.pdf)
[37](https://www.emergentmind.com/topics/causal-multimodal-information-bottleneck-camib)



Based on my research, I can now provide you with a comprehensive literature survey addressing your 50+ research questions on causal discovery, causal knowledge graphs, and their applications. Let me compile this information into a well-structured report.

# Comprehensive Literature Survey: Causal Discovery, Causal Knowledge Graphs, and Applications

This literature survey synthesizes current research across foundational theory, technical implementation, query processing, evaluation methodologies, domain-specific applications, and open challenges in causal AI systems as of 2024-2025. The field has experienced significant advances in differentiable causal discovery, large language model integration, and practical deployment across healthcare, finance, and climate science domains.

## Foundational Algorithms and Theoretical Framework

### State-of-the-Art Causal Discovery Approaches

The causal discovery landscape consists of three dominant paradigms: constraint-based, score-based, and function-based methods. **Constraint-based algorithms** (PC, FCI, RFCI) rely on conditional independence tests to identify causal structure by testing for dependencies between variable pairs given different conditioning sets, aiming to recover the Markov equivalence class of the true causal graph. These methods begin with a fully connected undirected graph and iteratively eliminate edges when conditional independence is detected. **Score-based methods** (GES, GFCI, NOTEARS) optimize an objective function defined over the causal graph structure, enabling greater flexibility than constraint-based approaches. Recent empirical comparisons demonstrate that score-based algorithms generally achieve higher accuracy in simulation studies compared to constraint-based methods, though the relative performance depends substantially on data characteristics and problem settings.[1][2][3][4][5]

Emerging **function-based approaches** directly estimate structural equation models without intermediate graph construction, representing a paradigm shift toward continuous optimization formulations. The NOTEARS algorithm exemplifies this trend by reformulating causal discovery as a continuous optimization problem with differentiable acyclicity constraints, enabling scalable neural network-based approaches. However, recent work (DARING) has revealed limitations in NOTEARS' robustness to heterogeneous noise, proposing enhanced methods incorporating explicit residual independence constraints.[6][7]

Innovation in causal discovery has accelerated through neural architectures and differentiable frameworks. A 2024 method called ReX leverages explainability techniques with Shapley values coupled to machine learning models, achieving state-of-the-art performance on synthetic and real protein-signaling datasets with precision of 0.952. Deep learning approaches designed for high-dimensional settings (D²CL) have demonstrated exceptional scalability, successfully learning causal structures with up to 50,000 variables—a capability unmatched by traditional methods.[8][9]

### Latent Confounders and Identifiability Challenges

One of causal discovery's most pressing challenges involves latent (unobserved) confounders—hidden common causes of measured variables. When the causal Markov condition is violated due to unobserved confounding, standard causal discovery algorithms produce spurious edges. Recent work has developed nonlinear causal models incorporating hidden confounders, demonstrating identifiability from observational data alone using variational autoencoders. This advance directly addresses a fundamental limitation in traditional approaches that require the causal sufficiency assumption.[10]

Pearl's do-calculus provides the theoretical foundation for determining query identifiability in the presence of latent variables. When causal graphs correctly represent underlying structures and queries are identifiable according to do-calculus, latent variable models (LVMs) produce consistent estimates of causal effects. The identifiability question becomes critical in application domains like healthcare where missing variables often represent unmeasured confounding.[11]

### Integration of Large Language Models into Discovery Pipelines

A paradigm shift is occurring in causal discovery methodology through large language model integration. LLMs can enhance traditional statistical discovery through three mechanisms: (1) direct causal inference from natural language descriptions, (2) post-refinement of statistically derived structures through LLM reasoning, and (3) integration of prior knowledge into statistical methods. However, empirical evaluation reveals important limitations: **fine-tuned models substantially outperform prompt-based LLMs** for causal relation classification, with improvements up to 20.5 F1 points. This finding contradicts recent trends where LLMs excel at diverse NLP tasks, suggesting that causal relationship identification requires exposure to domain-specific patterns through supervised learning.[12][13]

The Causal Modeling Agent (CMA) framework demonstrates how LLMs can be combined with deep structural causal models, employing metadata-based LLM reasoning alongside data-driven inference. Recent benchmarks like CausalGraph2LLM enable systematic evaluation of LLMs' abilities to reason over causal graphs and answer counterfactual queries, establishing evaluation frameworks previously lacking in the field.[14][12]

## Technical Implementation: Neural Architectures and Extraction Methods

### Causal Relation Extraction from Unstructured Text

Modern causal relation extraction from text employs diverse neural architectures suited to different linguistic structures. **Recurrent neural networks** process text sequentially to capture sentence context, while **convolutional neural networks** identify position-invariant causal patterns in text. **Graph convolutional networks** model dependencies between sentence components, enabling capture of complex causal structures. Context-enhanced transformers have emerged as particularly effective, improving generalization through reduced dependence on sentence-specific patterns.[15]

A 2024-2025 approach combines SpERT models for entity and relation extraction with fine-tuned BERT classification to segment documents and extract cause-and-effect triples at scale. The resulting pipeline constructs graph databases in Neo4j, enabling Cypher queries over extracted causal relationships. This two-stage approach integrates preprocessing, compression, entity/relation extraction, and database ingestion into a unified workflow applicable to maintenance documentation and domain-specific corpora.[16]

### Graph Neural Networks for Causal Inference

Graph neural networks have proven effective for causal analysis due to their capacity as universal approximators and ability to handle multi-modal learning. GNNs aggregate neighbor representations through iterative updates, learning node embeddings that capture causal structure. Recent architectures incorporate **Granger causality analysis** within graph attention networks to simultaneously model temporal dynamics and causal dependencies. The Temporal Causal Graph Attention (TCGA/TCAT) framework enhances GNN capacity by weighting edges with temporal functions, enabling representation of historical fact sequences with varying temporal intervals and causal dependencies.[17][18]

## Query Processing, Reorientation, and Dynamic Reasoning

### Natural Language Query Translation and Semantic Mapping

Translating natural language to causal queries requires breaking the translation process into manageable sub-tasks: question analysis/syntactic parsing, question type classification, phrase mapping to knowledge graph entities, and query ranking. Tree-LSTM models rank candidate queries by computing syntactic and semantic similarity to input questions. Entity detection ensembles improve coverage compared to simple lexicalization approaches, while lemmatization reduces inflectional forms to common bases.[19]

Recent advances in causal retrieval-augmented generation (CausalRAG) extend this work by constructing causal graphs from documents and tracing causal relationships to preserve contextual continuity. Unlike standard RAG systems relying on semantic similarity, CausalRAG retrieves documents that are both relevant and causally grounded, reducing hallucinations and improving faithfulness.[20]

### Counterfactual and Intervention Queries

Causal query types fundamentally differ in their graph requirements. **Causal queries** discover causality through intervention (Pearl's do(X=x) notation), distinguishing causal relationships from mere correlation. **Counterfactual queries** reason about alternative scenarios given observed information, exemplified by questions like "Would outcome Y have occurred if we had intervened to set X=x?". **Explanatory queries** require tracing causal paths to explain observed outcomes. Each query type necessitates different graph adaptations and inference mechanisms.[21][14]

Automated confounding variable identification and adjustment represents an emerging capability. Recent fairness auditing frameworks identify confounders through causal sensitivity analysis, enabling systematic quantification of their impacts on downstream inferences.[22]

### Dynamic Graph Updates and Temporal Reasoning

Contemporary knowledge graphs increasingly incorporate temporal dimensions, with frameworks like HTCGAT (Latent History Learning for Temporal Causal Graph Attention) addressing cold-start problems for newly introduced entities. By merging entity similarity with temporal decay functions, these systems acquire latent historical data for entities with insufficient direct history.[18]

A 2025 framework for dynamic causal structure discovery enables time-varying causal relationships. By integrating basis approximation methods into score-based discovery, these approaches capture both contemporaneous and time-lagged causal relationships while allowing them to vary across time periods. This capability proves essential for domains like biomedicine where causal structures evolve as new treatments emerge or understanding develops.[23]

## Evaluation, Verification, and Quality Assessment

### Metrics and Benchmarks for Causal Knowledge Graphs

Evaluating causal knowledge graph quality requires multi-faceted approaches. The measurement framework proposed at AAAI-23 introduces three categories of metrics: **K Score** (based on Science of Science), **I Score** (information theory), and **C Score** (causal perspective). Causal-specific metrics include causal sufficient score, causal efficient score, and causal informative score, defined relative to ground truth causal graphs and equivalent sub-graphs.[24]

Benchmarks for causal relation extraction and reasoning have proliferated, including QALD-7 (Question Answering over Linked Data Challenge) and LC-QuAD (Large-Scale Complex Question Answering Dataset) for evaluating NL-to-SPARQL translation. More recently, CausalGraph2LLM provides a comprehensive benchmark encompassing various causal graph settings to assess LLM performance on causal reasoning tasks.[14][19]

### Detection and Prevention of Spurious Correlations

Spurious correlations—non-causal associations exploited by classifiers—present a persistent challenge. NeurIPS 2023 work (AutoACER) proposes automated detection methods estimating each attribute's causal effect on labels. The method identifies spurious attributes and applies regularization to mitigate classifier reliance on them. While causal effect identification is not always possible, the framework proves empirically robust even under noisy effect estimation.[25]

### Simpson's Paradox and Statistical Paradoxes

Simpson's Paradox—where association directions reverse after conditioning on a third variable—illustrates fundamental differences between correlation and causation. Modern causal frameworks resolve such paradoxes through graphical models where confounding concepts explain apparent contradictions. The key insight is that correlation relationships lack robustness across contexts due to unknown confounders, while causal relationships, once established through proper adjustment, transfer across situations.[26][27]

## Domain-Specific Applications

### Healthcare: Treatment Recommendation and Adverse Event Prediction

Healthcare represents a principal application domain for causal knowledge graphs. Knowledge graph-driven medicine recommendation systems like KGDNet leverage graph neural networks with longitudinal electronic health records to predict drug-drug interactions (DDIs) and enable safe medication recommendations. By constructing admission-wise medical knowledge graphs for each patient and learning through GNNs, these systems simultaneously optimize recommendation accuracy while minimizing dangerous drug combinations.[28]

Treatment recommendation systems aim to suggest personalized medications based on individual health conditions, improving treatment outcomes and physician decision support. Knowledge graphs also enable broader applications including COVID-19 transmission analysis through patient activity networks and chronic disease management systems combining knowledge graphs with big data analytics.[29]

### Finance: Risk Assessment and Portfolio Management

A 2024 framework (FinCARE) integrates causal discovery with financial knowledge graphs extracted from SEC 10-K filings and LLM reasoning. The hybrid approach enhances three causal discovery paradigms—constraint-based (PC), score-based (GES), and continuous optimization (NOTEARS)—by encoding knowledge graph constraints algorithmically and leveraging LLM reasoning. Results demonstrate substantial improvements: PC achieves +36% F1, GES +100%, and NOTEARS +366% compared to baseline statistical methods. Critically, the framework enables reliable counterfactual predictions (mean absolute error: 0.003610) with perfect directional accuracy for interventions, supporting proactive causal analysis for portfolio management.[30]

### Climate Science: Attribution and Prediction

Climate science applications employ causal inference frameworks to attribute ecological shifts to climate change in observational settings. A five-step framework guides researchers through theoretical foundation description, appropriate dataset selection, causal relationship estimation, counterfactual scenario simulation, and robustness evaluation. Case studies on pinyon pine ecosystems in North America demonstrate the approach's utility for quantifying ecosystem responses in rapidly warming environments.[31]

### Fairness and Bias Detection

Causal approaches to algorithmic fairness have matured significantly. The "peer-induced fairness" framework combines counterfactual fairness with peer comparison strategies, providing reliable auditing tools for algorithmic bias. Unlike traditional fairness metrics, causal frameworks can distinguish whether adverse decisions result from algorithmic discrimination or inherent subject limitations, enhancing transparency required by regulations like the EU AI Act. Causal sensitivity analysis frameworks enable ML practitioners to quantify impacts of measurement biases on fairness evaluations.[32][22]

## Integration with Large Language Models and Deep Learning

### Improving Factual Consistency and Robustness

Causal knowledge graphs promise to improve LLM factual consistency by grounding retrieval in causal reasoning. CausalRAG demonstrates how integrating causal graphs into retrieval-augmented generation preserves contextual continuity, reduces hallucinations, and enhances answer faithfulness compared to standard and graph-based RAG approaches.[20]

### Combining Causal Inference with Deep Learning

Combining causal frameworks with deep neural networks enhances prediction robustness. Meta-learning approaches for personalized biomedical causal graph learning share knowledge across correlated structure learning tasks, reducing structural Hamming distance by 50-75% compared to baseline algorithms while decreasing false discovery rate by 20-30%.[33]

### Causal Representation Learning

Recent advances in causal representation learning enhance knowledge graph embeddings by capturing causal semantics rather than purely distributional properties. This shift from statistical to causal embeddings promises more interpretable and generalizable representations.[12]

## Open Problems and Future Directions

### Scalability and High-Dimensional Challenges

While deep learning approaches have enabled scaling to thousands of variables, challenges remain in interpreting structures learned at such scales and validating discovered relationships without domain expertise. The gap between empirical performance and theoretical understanding grows as dimensionality increases.[9]

### Handling Contradictory and Uncertain Information

Real-world knowledge graphs frequently contain contradictory information from multiple sources with varying reliability. Existing frameworks provide limited mechanisms for probabilistic resolution of such conflicts while maintaining causal semantics.[20]

### Privacy and Ethical Considerations

Building causal graphs from sensitive data raises critical privacy concerns. Current approaches delete personal data after 30 days (as in Comet integration) but lack principled frameworks for balancing causal learning utility with privacy preservation under differential privacy constraints.[20]

### Unified Evaluation and Standardization

Despite proliferating benchmarks and datasets, the field lacks standardized evaluation protocols comparable across studies. Domain-specific applications have unique requirements diverging from generic evaluation frameworks.[12]

## Conclusion

The causal AI field has matured substantially, moving from purely statistical approaches to hybrid frameworks combining constraint-based/score-based discovery, neural architectures, and LLM reasoning. Key advances include (1) scalable differentiable discovery methods handling high-dimensional settings, (2) effective causal relation extraction from text using fine-tuned neural models, (3) temporal and dynamic causal graph frameworks, and (4) successful applications across healthcare, finance, and climate science.

Critical remaining challenges center on handling latent confounders, developing more robust discovery in high-dimensional settings, standardizing evaluation practices, and establishing privacy-preserving mechanisms for sensitive domains. The integration of LLMs shows promise but requires careful calibration—fine-tuned models substantially outperform prompting-based approaches for causal reasoning tasks. Future research should prioritize unified benchmarks, handling uncertain/contradictory information, and principled privacy frameworks while continuing to expand domain-specific applications demonstrating practical value in high-stakes decision-making contexts.[2][3][13][27][1][15][11][16][6][18][29][24][21][28][26][25][10][32][19][22][9][23][31][30][33][14][12][20]

[1](https://arxiv.org/abs/1611.03977)
[2](https://pmc.ncbi.nlm.nih.gov/articles/PMC6510516/)
[3](https://arxiv.org/pdf/2305.10032.pdf)
[4](https://compass.onlinelibrary.wiley.com/doi/10.1111/phc3.12470)
[5](https://fiveable.me/causal-inference/unit-10/constraint-based-algorithms/study-guide/5iUOkVRLvyUnYSGm)
[6](https://pengcui.thumedialab.com/papers/DARING.pdf)
[7](https://www.fujitsu.com/global/documents/about/research/article/202410-causal-knowledge-graph/202410_White-Paper-Casual-Knowledge-Graph_EN.pdf)
[8](https://www.sciencedirect.com/science/article/pii/S0031320325011549)
[9](https://www.nature.com/articles/s42256-023-00744-z)
[10](https://proceedings.mlr.press/v202/kaltenpoth23a.html)
[11](https://academic.oup.com/bioinformatics/article/38/Supplement_1/i350/6617530)
[12](https://www.ijcai.org/proceedings/2025/1186.pdf)
[13](https://arxiv.org/html/2406.16899v1)
[14](https://arxiv.org/html/2410.15939v1)
[15](https://www.cambridge.org/core/journals/research-synthesis-methods/article/capturing-causal-claims-a-finetuned-text-mining-model-for-extracting-causal-sentences-from-social-science-papers/E76E6EFB3373DE4FE6D9DCDB56271CEE)
[16](https://www.sciencedirect.com/science/article/pii/S0166361524000381)
[17](https://arxiv.org/pdf/2311.14994.pdf)
[18](https://www.sciencedirect.com/science/article/abs/pii/S0957417425037054)
[19](https://pmc.ncbi.nlm.nih.gov/articles/PMC7799375/)
[20](https://arxiv.org/html/2503.19878v1)
[21](https://cedar.buffalo.edu/~srihari/CSE674/Chap21/21.2-Counterfactuals.pdf)
[22](https://proceedings.neurips.cc/paper_files/paper/2024/file/f7be3ebca4980b59fe3f665011115395-Paper-Datasets_and_Benchmarks_Track.pdf)
[23](https://arxiv.org/html/2501.06534v1)
[24](https://r2hcai.github.io/AAAI-23/files/CameraReadys/9.pdf)
[25](https://papers.nips.cc/paper_files/paper/2023/hash/42770daf4a3384b712ea9c36e9279998-Abstract-Conference.html)
[26](https://alexdeng.github.io/causal/simpson.html)
[27](https://plato.stanford.edu/entries/paradox-simpson/)
[28](https://www.nature.com/articles/s41598-024-75784-5)
[29](https://arxiv.org/html/2306.04802v4)
[30](https://arxiv.org/html/2510.20221v1)
[31](https://onlinelibrary.wiley.com/doi/10.1111/ele.70192?af=R)
[32](https://arxiv.org/html/2408.02558v4)
[33](https://pmc.ncbi.nlm.nih.gov/articles/PMC11129385/)
[34](https://www.its.caltech.edu/~fehardt/papers/HEJ_UAI2014.pdf)
[35](https://docs.actable.ai/causal_discovery.html)
[36](https://research.ibm.com/publications/interventional-causal-discovery-in-a-mixture-of-dags)
[37](https://www.pywhy.org)
[38](https://github.com/py-why)